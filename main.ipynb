{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d8yj3Gvf8xA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tempfile\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ1TSKbdnlgU"
      },
      "source": [
        "# Help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTn4VnQGnozO"
      },
      "outputs": [],
      "source": [
        "def get_features(data):\n",
        "  features = list(data)\n",
        "  features.remove('label')\n",
        "  return features\n",
        "\n",
        "def onehot_encode(data_train, data_test):\n",
        "  X_train = data_train.loc[:, data_train.columns != 'label']\n",
        "  train_test_features = pd.concat([X_train, data_test])\n",
        "  to_encode = []\n",
        "  for c in get_features(data_train):\n",
        "      if train_test_features[c].dtypes==object:\n",
        "        to_encode.append(c)\n",
        "  train_test_features = pd.get_dummies(train_test_features, columns = to_encode)\n",
        "  train = train_test_features.head(len(data_train))\n",
        "  train['label']=data_train['label'].values\n",
        "  test = train_test_features.tail(len(data_test))\n",
        "  return train, test\n",
        "def ord_encode(data_train, data_test):\n",
        "  X_train = data_train.loc[:, data_train.columns != 'label']\n",
        "  train_test_features = pd.concat([X_train, data_test])\n",
        "  to_encode = []\n",
        "  for c in get_features(data_train):\n",
        "      if train_test_features[c].dtypes==object:\n",
        "        train_test_features[c]= train_test_features[c].map({'low':0.1, 'medium':0.5, 'high':0.9})\n",
        "  train = train_test_features.head(len(data_train))\n",
        "  train['label']=data_train['label'].values\n",
        "  test = train_test_features.tail(len(data_test))\n",
        "  return train, test\n",
        "\n",
        "def feature_selection_var_based(train_data, test_data, frac_to_throw):\n",
        "  \n",
        "  vars = []\n",
        "  for c in get_features(train_data):\n",
        "    vars.append(train_data[c].var())\n",
        "  vars.sort()\n",
        "  \n",
        "  th = vars[int(len(vars) * frac_to_throw)]\n",
        "  print(th)\n",
        "  to_throw = []\n",
        "  for c in get_features(train_data):\n",
        "    if train_data[c].var()<=th:\n",
        "      to_throw.append(c)\n",
        "  print('to throw for', frac_to_throw)\n",
        "  print(len(to_throw))\n",
        "  print(to_throw)  \n",
        "  return train_data.drop(to_throw, axis=1), test_data.drop(to_throw, axis=1)\n",
        "\n",
        "\n",
        "def median_imputing_and_scaling(train_data, test_data):\n",
        "  y = list(train_data['label'])\n",
        "  features = get_features(train_data)\n",
        "  train_test_features = pd.concat([train_data[features], test_data[features]])\n",
        "  tmp = train_test_features.loc[:,features].values\n",
        "  tmp = SimpleImputer(strategy='median').fit_transform(tmp)\n",
        "  tmp = StandardScaler().fit_transform(tmp) \n",
        "  train_test_features[features]=tmp\n",
        "\n",
        "  train = train_test_features.head(len(train_data))\n",
        "  train['label']=train_data['label'].values\n",
        "  test = train_test_features.tail(len(test_data))\n",
        "  return train, test\n",
        "\n",
        "def feature_selection(X_train, X_test, y_train, kv):\n",
        "  selection = SelectKBest(score_func=mutual_info_classif, k=kv)\n",
        "  X_train = selection.fit_transform(X_train, y_train) \n",
        "  X_test = selection.transform(X_test)\n",
        "  print(\"feature sel : k=\", kv)\n",
        "  return X_train, X_test\n",
        "\n",
        "def sample_df(input_df, rs):\n",
        "  train_df, val_df = train_test_split(input_df, test_size=0.1, random_state=rs)\n",
        "\n",
        "  y_train = np.array(train_df.pop('label'))\n",
        "  y_val = np.array(val_df.pop('label'))\n",
        "\n",
        "  X_train = np.array(train_df)\n",
        "  X_val = np.array(val_df)\n",
        "\n",
        "  return X_train, X_val, y_train, y_val\n",
        "\n",
        "def oversample(X,y, f=1):\n",
        "  is_pos = y == 1\n",
        "  X_pos = X[is_pos]\n",
        "  X_neg = X[~is_pos]\n",
        "\n",
        "  y_pos = y[is_pos]\n",
        "  y_neg = y[~is_pos]\n",
        "\n",
        "  ids = np.arange(len(X_pos))\n",
        "  choices = np.random.choice(ids,int(f*len(X_neg)))\n",
        "\n",
        "  X_pos = X_pos[choices]\n",
        "  y_pos = y_pos[choices]\n",
        "\n",
        "  X = np.concatenate([X_pos, X_neg], axis=0)\n",
        "  y = np.concatenate([y_pos, y_neg], axis=0)\n",
        "\n",
        "  order = np.arange(len(X))\n",
        "  np.random.shuffle(order)\n",
        "  X = X[order]\n",
        "  y = y[order]\n",
        "  return X,y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y55Lv67qU82k"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1lCdF8Xd8Yb"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_train.csv', sep=',')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_test.csv', sep=',')\n",
        "df_train_enc, df_test_enc = onehot_encode(df_train, df_test) # saved in *-enc.csv\n",
        "df_train_35, df_test_35 = feature_selection_var_based(df_train_enc, df_test_enc, 0.35)\n",
        "df_train_fill, df_test_fill = median_imputing_and_scaling(df_train_35, df_test_35)\n",
        "#df_test_fill.to_csv('/content/drive/MyDrive/a5/ML-A5-2022_test-full-35-median.csv')\n",
        "#df_train_fill.to_csv('/content/drive/MyDrive/a5/ML-A5-2022_train-full-35-median.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K53umd7YutRu"
      },
      "source": [
        "# Load final data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itest_df = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_test.csv', index_col=0)\n"
      ],
      "metadata": {
        "id": "tq-LWUTFgIzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itest_df.head()"
      ],
      "metadata": {
        "id": "QEFkESQGgc4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysWSqEwEZm8o"
      },
      "outputs": [],
      "source": [
        "raw_df = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_train-full-35-median.csv', index_col=0)\n",
        "#test_df = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_test-full-35-median.csv', index_col=0)\n",
        "#raw_df.head()\n",
        "#iraw_df = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_train.csv', index_col=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iraw_df.head()"
      ],
      "metadata": {
        "id": "8IbZo439h19j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.head()"
      ],
      "metadata": {
        "id": "_GbADW1WaCac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_train = list(raw_df.columns)\n",
        "col_train.remove('label')\n",
        "\n",
        "col_test = list(test_df.columns)\n"
      ],
      "metadata": {
        "id": "TJJQkdi5aPx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in col_train:\n",
        "  if c not in col_test:\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "FhrheSeta6L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  col_train"
      ],
      "metadata": {
        "id": "eEsNoZoBa4B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(raw_df, test_size=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "bXqhQ3U1XZN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(train_df.pop(\"label\"))\n",
        "X_train = np.array(train_df)\n",
        "y_test = np.array(val_df.pop(\"label\"))\n",
        "X_test = np.array(val_df)"
      ],
      "metadata": {
        "id": "24CmGegnXlaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = feature_selection(X_train, X_test, y_train, 250)  \n",
        "X_train, y_train = oversample(X_train, y_train)\n",
        "\n",
        "clf = HistGradientBoostingClassifier(max_depth=3, max_leaf_nodes=20,\n",
        "                            min_samples_leaf=25, random_state=42,\n",
        "                            scoring='balanced_accuracy', max_iter=200)\n",
        "clf.fit(X_train, y_train)\n",
        "ypred = clf.predict(X_test)\n",
        "balanced_accuracy_score(y_test, ypred)"
      ],
      "metadata": {
        "id": "ehARet3uX_5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMGTdsvaBd-S"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLocZ_vNCK4c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "# split :\n",
        "# 80-20 : 77, 78, 78\n",
        "# 90-10 : 82, 79, 81\n",
        "# 95-5 : 76, 80; 79.5; 81\n",
        "# 97.5-2.5\n",
        "# ~77 % bcr estimation\n",
        "k=250\n",
        "bcr1=0\n",
        "bcr2 = 0\n",
        "models = []\n",
        "for f in (0.05, 0.1, 0.20, 0.30, 0.40):\n",
        "  print(f)\n",
        "  bcr1 = 0\n",
        "  bcr2 = 0\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    X_train, X_val, y_train, y_val = sample_df(raw_df, i)\n",
        "    X_train, X_val = feature_selection(X_train, X_val, y_train, k)  \n",
        "    X_train, y_train = oversample(X_train, y_train)\n",
        "\n",
        "    clf = HistGradientBoostingClassifier(max_depth=3, max_leaf_nodes=20,\n",
        "                                min_samples_leaf=25, random_state=42,\n",
        "                                scoring='balanced_accuracy', max_iter=200)\n",
        "\n",
        "\n",
        "    \n",
        "    clf.fit(X_train, y_train)\n",
        "    ypred = clf.predict(X_val)\n",
        "    print(balanced_accuracy_score(y_val, ypred))\n",
        "    bcr1+=balanced_accuracy_score(y_val, ypred)\n",
        "    print()\n",
        "  print(bcr2/10)\n",
        "  print(bcr1/10)\n",
        "  bcr2/=10\n",
        "  bcr1/=10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB-nJRq5NvWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5kUTeXUFfFq"
      },
      "outputs": [],
      "source": [
        "# majority vote among different models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tGU6HsX4E3s"
      },
      "outputs": [],
      "source": [
        "test[get_features(test)]\n",
        "test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hGHwaBb36mn"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = sample_df(train, 6)\n",
        "X_train, X_val = feature_selection(X_train, test[get_features(test)], y_train, k)  \n",
        "X_train, y_train = oversample(X_train, y_train)\n",
        "\n",
        "clf = HistGradientBoostingClassifier(max_depth=3, max_leaf_nodes=20,\n",
        "                              min_samples_leaf=25, random_state=42,\n",
        "                              scoring='balanced_accuracy')\n",
        "  \n",
        "clf.fit(X_train, y_train)\n",
        "balanced_accuracy_score(test['label'], clf.predict(X_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDcMxZkw61kN"
      },
      "outputs": [],
      "source": [
        "balanced_accuracy_score(test['label'], clf.predict(X_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7esKbWRUJ8y1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# ~77 % bcr estimation\n",
        "k=250\n",
        "bcr = 0\n",
        "for i in range(5):\n",
        "  print(i)\n",
        "  X_train, X_val, y_train, y_val = sample_df(raw_df, 1)\n",
        "  X_train, X_val = feature_selection(X_train, X_val, y_train, k)  \n",
        "  X_train, y_train = oversample(X_train, y_train)\n",
        "\n",
        "  clf = HistGradientBoostingClassifier(max_depth=3, max_leaf_nodes=20,\n",
        "                               min_samples_leaf=25, random_state=42,\n",
        "                               scoring='balanced_accuracy') \n",
        "  clf.fit(X_train, y_train)\n",
        "  ypred = clf.predict(X_val)\n",
        "  print(balanced_accuracy_score(y_val, ypred))\n",
        "  bcr+=balanced_accuracy_score(y_val, ypred)\n",
        "print(bcr/5)\n",
        "bcr/=5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy88jkAS828i"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nadsn3WM8a_z"
      },
      "outputs": [],
      "source": [
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqpOCJVHe4d8"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/a5/ML-A5-2022_test-full-35-median.csv', index_col=0)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnoLVn9ZFbOO"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35Ga_llE9BiM"
      },
      "outputs": [],
      "source": [
        "X_test = np.array(test_df)\n",
        "X_train, _, y_train, _ = sample_df(raw_df, i)\n",
        "print(X_train.shape)\n",
        "X_train, X_test = feature_selection(X_train, X_test, y_train, 250)  \n",
        "X_train, y_train = oversample(X_train, y_train)\n",
        "\n",
        "clf = HistGradientBoostingClassifier(max_depth=3, max_leaf_nodes=20,\n",
        "                               min_samples_leaf=25, random_state=42,\n",
        "                               scoring='balanced_accuracy') \n",
        "clf.fit(X_train, y_train)\n",
        "ypred = clf.predict(X_test)\n",
        "np.count_nonzero(ypred == 1)\n",
        "test_df['Prediction']=ypred\n",
        "pred_df = test_df['Prediction']\n",
        "pred_df.to_csv('/content/drive/MyDrive/a5/histPrediction.csv')\n",
        "pred_df.to_csv('histPredictionbr.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0HaXr2c_aPN"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1WQ5EtGiU4O"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}